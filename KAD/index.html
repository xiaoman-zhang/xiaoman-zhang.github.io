<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->

<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

	<title>KAD: Knowledge-enhanced auto-diagnosis of chest X-ray images</title>
</head>

<body>
	<br>
	<center>
	<span style="font-size:36px">KAD: Knowledge-enhanced auto-diagnosis of chest X-ray images</span><br><br><br>
	</center>
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://chaoyi-wu.github.io/">Chaoyi Wu</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://weidixie.github.io/">Weidi Xie</a><sup>2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
	      <center>
                <span style="font-size:16px"><a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a><sup>1</sup></span>
                </center>
		</td>
                    <td align="center" width="160px">	    
              <center>
                <span style="font-size:16px"><a href="https://mediabrain.sjtu.edu.cn/">Yanfeng Wang</a><sup>1</sup></span>
                </center>
            </tr>

        </tbody></table><br>
	
	  <table align="center" width="700px">
            <tbody><tr>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>1</sup>CMIC, Shanghai Jiao Tong University</span>
                </center>
                </td>
        </tr></tbody></table>
	
	<table align="center" width="700px">
            <tbody><tr>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">Code
                    <a href="https://github.com/xiaoman-zhang/KAD"> [GitHub]</a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    Paper <a href="https://arxiv.org"> [arXiv]</a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    Cite <a href="./cite.txt"> [BibTeX]</a>
                  </span>
                </center>
              </td>
            </tr></tbody>
      </table>
	
      <br><hr>
      <center><h2> Abstract </h2> </center>
      <p style="text-align:justify; text-justify:inter-ideograph;">
      <left>
	      Foundation models pre-trained on a broad system of general data demonstrate significant gains across various domains including computer vision and natural language processing. 
        However, the application in the medical domain is still in the initial stage, as the problems in medical diagnosis naturally require long-tailed and fine-grained knowledge understanding, thus heavily relying on expertise from clinicians. 
        Here we propose a medical knowledge-enhanced vision-language pre-training method for auto-diagnosis of chest X-ray images, termed as Knowledge-enhanced Auto Diagnosis~(KAD), 
        which leverages domain expert knowledge from the medical knowledge base Unified Medical Language System (UMLS) to improve vision-and-language understanding and facilitate the zero-shot disease diagnosis. 
        KAD demonstrates superior ability in auto-diagnosis of unseen pathologies, with zero-shot performance significantly higher than precious medical VLP models, and even comparable to fully-supervised approaches. 
        Notably, this is the first foundation model in X-ray with zero-shot performance comparable or exceeding the average for expert radiologists.
      </left></p>
      <br><hr>
      
      <br><hr>
      <center> <h2> Architecture </h2> </center>
      <p style="text-align:justify; text-justify:inter-ideograph;">
      <left>
      Overview of the KAD workflow. 
      (a), Knowledge base used for training the text encoder. It contains two parts, knowledge graph consisting of concept-relation-concept triplets and concept info list consisting of concept-definition pairs.
      (b), In the first stage, the text encoder is trained to learns textual representations by maximizing similarities between positive pairs.
      (c), In the second stage, we employ the pre-trained text encoder to perform image-text contrastive learning with paired chest X-rays and entities extracted from the radiology reports and optimize a Disease Query Network (DQN) for classification.
      (d), During the inference stage, we simply encode the disease name as a query input, and DQN will output the probability that the pathology is present in the input image.
      </left></p>
      <p><img class="left"  src="./resources/KAD.png" width="800px"></p>
      <br><hr>
      
      <br><hr>
      <center><h2>Results</h2></center>
      <p><b>R1: Padchest </b> </p>
      <p><left>
	      Comparison of KAD with SOTA medical image-text pre-training models on unseen radiographic findings in the PadChest dataset.
      </left></p>
      <p><img class="center"  src="./resources/padchest.png" width="800px"></p>

      <p><b>R2: ChestXray14 </b> </p>	
      <p><left>
	     Comparison of proposed KAD with SOTA self-supervised baseline models and medical image-text pre-training models on ChestXray14 with different ratio of labeled data used.
      </left></p>
      <p><img class="center"  src="./resources/chestxray14.png" width="800px"></p>
    
      <p><b>R3: CheXpert </b> </p>	
      <p><left>
	    Comparisons of proposed KAD with SOTA medical image-text pre-training models and three board-certified radiologists on five competition pathologies in CheXpert dataset.
      </left></p>
      <p><img class="center"  src="./resources/chexpert.png" width="800px"></p>
    
      <p><b>Visualization </b> </p>
      <p><left>
	     Sample visualization of randomly chosen samples from NIH ChestXray14, we present both the original image (left) and an attention map generated from KAD (right). 
       In the original images, red boxes denote lesion areas annotated by radiologists. 
       In the attention maps, the red to blue spectrum are plot on the original image with red representing high attention regions and blue representing low attention.
      </left></p>
      <p><img class="center"  src="./resources/visualize.png" width="800px"></p>
      <br><hr>
	
      <br>
      <hr>
      <center> <h2> Acknowledgements </h2> </center>
      <p> 
	      Based on a template by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
      </p>
      <br>


<br>
</body>
</html>
