
<!DYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xiaoman Zhang</title>
  
  <meta name="author" content="Xiaoman Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    .publication {
      margin-bottom: 1.5rem;
    }
    .title {
      font-weight: bold;
      color: black;
      text-decoration: none;
    }
    .authors {
      margin: 0.25rem 0;
    }
    .venue {
      font-style: italic;
    }
    .highlight_author {
      font-weight: bold;
    }
  </style>
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Xiaoman Zhang (张小嫚) </name>
              </p>
              <p> 
                Hi, I am a postdoctoral fellow at Harvard University in the Department of Biomedical Informatics, working with <a href="https://pranavrajpurkar.com/">>Prof. Pranav Rajpurkar</a>. </p>
                <p>  
                I received my PhD in Shanghai Jiao Tong Universiy, advised by <a href="https://weidixie.github.io/">Prof. Weidi Xie</a> and <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Prof. Ya Zhang</a>.
		            I received my bachelor degree from School for the Gifted Young, University of Science and Technology of China in June 2019. 
              </p>
              <p> 
                My research interest focuses on Artificial Intelligence for Healthcare (AI4Health), with the ultimate goal of developing a generalist medical foundation model.
	      </p>                   
              <p style="text-align:center">
                <a href="mailto:xiaomanzhang.zxm@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=Zno4WggAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/xiaoman-zhang/">Github</a> &nbsp/&nbsp
                <!-- <a href="./files/CV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/XiaomanZhang99">Twitter</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image/zxm.png"><img style="width:100%;max-width:100%" alt="profile photo" src="image/zxm.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <div>
          <h2>Recent News</h2>
          <p>
            [11/2024] <a href="https://arxiv.org/pdf/2305.10415">1 paper</a> has been accepted by Communications Medicine.<br>
            [09/2024] <a href="https://www.nature.com/articles/s41467-024-54424-6">1 paper</a> has been accepted by Nature Communications.<br>
            [09/2024] <a href="https://aclanthology.org/2024.emnlp-main.836.pdf">1 paper</a> has been accepted by EMNLP.<br>
            [07/2024] Leaderboard for radiology report generation, <a href="https://rexrank.ai">ReXrank</a>, is released.<br>
            [07/2024] <a href="https://www.nature.com/articles/s41467-024-52417-z">1 paper</a> has been accepted by Nature Communications.<br>
            [07/2024] <a href="https://arxiv.org/pdf/2404.09942v1.pdf">1 paper</a> has been accepted by ECCV 2024(Oral).<br>
          </p>
        </div>

        <h2>Selected Research</h2>

        <div class="publication"> 
          <a href="https://arxiv.org/pdf/2411.18672" class="title">FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models</a><br>
          <div class="authors">Alice Heiman, <span class="highlight_author">Xiaoman Zhang</span>, Emma Chen, Sung Eun Kim, Pranav Rajpurkar</div>
          <div class="venue">Technical Report, 2024</div>
        </div>
        
        <div class="publication">
          <a href="https://arxiv.org/pdf/2407.16684" class="title">AutoRG-Brain: Grounded Report Generation for Brain MRI</a><br>
          <div class="authors">Jiayu Lei, <span class="highlight_author">Xiaoman Zhang</span>, Chaoyi Wu, Lisong Dai, Ya Zhang, Yanyong Zhang, Yanfeng Wang, Weidi Xie, Yuehua Li</div>
          <div class="venue">Technical Report, 2024</div>
        </div>

        <div class="publication">
          <a href="https://arxiv.org/pdf/2404.16754" class="title">RadGenome-Chest CT: A Grounded Vision-Language Dataset for Chest CT Analysis</a><br>
          <div class="authors"><span class="highlight_author">Xiaoman Zhang</span>, Chaoyi Wu, Ziheng Zhao, Jiayu Lei, Ya Zhang, Yanfeng Wang, Weidi Xie</div>
          <div class="venue">Technical Report, 2024</div>
        </div>

        <div class="publication">
          <a href="https://www.medrxiv.org/content/medrxiv/early/2024/06/24/2024.06.24.24309405.full.pdf" class="title">RaTEScore: A Metric for Radiology Report Generation</a><br>
          <div class="authors">Weike Zhao, Chaoyi Wu, <span class="highlight_author">Xiaoman Zhang</span>, Ya Zhang, Yanfeng Wang, Weidi Xie</div>
          <div class="venue">EMNLP, 2024</div>
        </div>

        <div class="publication">
          <a href="https://arxiv.org/pdf/2404.09942v1.pdf" class="title">Knowledge-enhanced Visual-Language Pretraining for Computational Pathology</a><br>
          <div class="authors">Xiao Zhou, <span class="highlight_author">Xiaoman Zhang</span>, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie</div>
          <div class="venue">ECCV (Oral), 2024</div>
        </div>

        <div class="publication"> 
          <a href="https://arxiv.org/pdf/2402.13963.pdf" class="title">Towards Building Multilingual Language Model for Medicine</a><br>
          <div class="authors">Pengcheng Qiu*, Chaoyi Wu*, <span class="highlight_author">Xiaoman Zhang</span>, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, Weidi Xie</div>
          <div class="venue">Nature Communications, 2024</div>
        </div>

        <div class="publication"> 
          <a href="https://xiaoman-zhang.github.io/PMC-VQA/" class="title">Towards Generalist Foundation Model for Radiology by Leveraging Web-scale 2D & 3D Medical Data</a><br>
          <div class="authors">Chaoyi Wu*,<span class="highlight_author">Xiaoman Zhang*</span>, Yanfeng Wang, Ya Zhang, Weidi Xie</div>
          <div class="venue">Technical Report, 2024</div>
        </div>
        
        <div class="publication"> 
          <a href="https://xiaoman-zhang.github.io/PMC-VQA/" class="title">PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering</a><br>
          <div class="authors"><span class="highlight_author">Xiaoman Zhang*</span>, Chaoyi Wu*, Ziheng Zhao, Weixiong Lin, Yanfeng Wang, Ya Zhang, Weidi Xie</div>
          <div class="venue">Communications Medicine, 2024</div>
        </div>

        <div class="publication"> 
          <a href="https://arxiv.org/pdf/2304.14454.pdf" class="title">PMC-LLaMA: Towards Building Open-source Language Models for Medicineg</a><br>
          <div class="authors">Chaoyi Wu*, Weixiong Lin*,<span class="highlight_author">Xiaoman Zhang</span>, Yanfeng Wang, Ya Zhang, Weidi Xie</div>
          <div class="venue">Journal of the American Medical Informatics Association, 2024</div>
        </div>

        <div class="publication">
          <a href="https://xiaoman-zhang.github.io/KAD/" class="title">Knowledge-enhanced Visual-Language Pre-training on Chest Radiology Images</a><br>
          <div class="authors"><span class="highlight_author">Xiaoman Zhang</span>, Chaoyi Wu, Yanfeng Wang, Ya Zhang, Weidi Xie</div>
          <div class="venue">Nature Communications, 2023</div>
        </div>

        <div class="publication">
          <a href="https://arxiv.org/pdf/2303.07240" class="title">PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents</a><br>
          <div class="authors">Weixiong Lin*, Ziheng Zhao*, <span class="highlight_author">Xiaoman Zhang</span>, Chaoyi Wu, Yanfeng Wang, Ya Zhang, Weidi Xie</div>
          <div class="venue">MICCAI, 2023 (Final List of MICCAI Young Scientist Publication Impact Award)</div>
        </div>

        <div class="publication">
          <a href="https://chaoyi-wu.github.io/MedKLIP/" class="title">MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training in Radiology</a><br>
          <div class="authors">Chaoyi Wu, <span class="highlight_author">Xiaoman Zhang</span>, Yanfeng Wang, Ya Zhang, Weidi Xie</div>
          <div class="venue">ICCV, 2023</div>
        </div>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
		Based on a template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
<!--for page update--> 
